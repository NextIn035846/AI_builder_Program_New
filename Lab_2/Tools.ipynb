{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b6852c",
   "metadata": {},
   "source": [
    "### Core capabilities of LLMs:\n",
    "\n",
    "1. Reasoning (Thinking): LLMs understand questions, break them down, and figure out how to answer them.\n",
    "\n",
    "2. Language Generation (Speaking): Once understood, LLMs generate word-by-word responses, effectively “speaking” back to users.\n",
    "\n",
    "### Limitations of LLMs:\n",
    "Despite their reasoning and language generation abilities, LLMs cannot perform real-world tasks such as booking train tickets, running code, interacting with APIs, or fetching live data (e.g., weather updates).\n",
    "This is likened to a human body with a brain (thinking and speaking) but no hands or legs (cannot execute tasks physically).\n",
    "## What is Tools?\n",
    "A tool is a Python function that is packaged so that the LLM can call it when needed. The LLM decides which tool to use and provides inputs; the tool executes and returns results to the LLM.\n",
    "\n",
    "### Types of Tools in LangChain\n",
    "\n",
    "#### Built-in Tools:\n",
    "These are pre-built, production-ready tools integrated into LangChain to cover common use cases such as Google searches, Wikipedia queries, running Python code, command-line operations, HTTP requests, sending Gmail messages, Slack integrations, database queries, and more. These tools require minimal setup and no coding from users.\n",
    "\n",
    "#### Custom Tools:\n",
    "When your use case is unique or specific to your application (e.g., a booking system for your company), you might need to build your own tools. Custom tools allow you to encapsulate your business logic or connect to your application’s APIs and databases directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c678d",
   "metadata": {},
   "source": [
    "### Built in tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d005e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out the latest news from India and around the world. Latest India news on Bollywood, Politics, Business, Cricket, Technology and Travel. Today's news: Get latest and Breaking News on Politics, Business, Lifestyle, Entertainment and Sports along with News updates from around the world. Also, find English News, live coverage … RBI governor Sanjay Malhotra’s commentary on India ’s GDP growth outlook in light of the stalemate on India -US trade deal would be an important point to watch out for the market. Most economists expect the RBI to maintain status quo on the repo rate as global economic uncertainty... AajTak: Hindi news (हिंदी समाचार) website, watch live tv coverages, Latest Khabar, Breaking news in Hindi of India , World, Sports, business, film and Entertainment.1:10. Todays uproar: Bulldozer action in Bareilly, a clampdown on violence? 5:08. Get breaking news alerts from India and follow today ’s live news updates in field of politics, business, technology, Bollywood, cricket and more.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "results = search_tool.invoke('top news in india today')\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa72d0",
   "metadata": {},
   "source": [
    "## ShellTool\n",
    "LangChain, the ShellTool is a built-in tool that allows an agent (or LLM) to execute shell (terminal/command-line) commands directly from within a LangChain workflow.\n",
    "\n",
    "It’s part of the LangChain Tools suite, and is especially useful when building agentic systems that need to interact with the local environment — for example, running scripts, checking files, or automating system tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8aa486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " whoami\n",
      "desktop-ritvsgj\\acer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tranining_Code\\AI_Builder_New_Program\\.venv\\Lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()\n",
    "results = shell_tool.invoke(\"whoami\")\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573870d",
   "metadata": {},
   "source": [
    "## Built In Tools List in langchain\n",
    "https://python.langchain.com/docs/integrations/tools/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1df20a",
   "metadata": {},
   "source": [
    "### What is a Custom Tool in LangChain?\n",
    "A custom tool is a tool that you, the developer, create from scratch to perform a specific, user-defined task that is not covered by the standard, pre-built tools.\n",
    "\n",
    "You create a custom tool when you want your LangChain agent to be able to do something unique to your application or to interact with a system that LangChain doesn't natively support.\n",
    "\n",
    "### Why Do We Need Custom Tools in LangChain?\n",
    "The need for custom tools arises because the possibilities for what you might want an AI agent to do are virtually limitless. The built-in tools cover common use cases, but for any real-world, specialized application, you'll almost certainly need to create your own.\n",
    "\n",
    "Here are the primary reasons why custom tools are essential in LangChain:\n",
    "\n",
    "1. To Connect to Proprietary or Internal APIs:\n",
    "This is one of the most common and powerful use cases. Imagine you want your agent to:\n",
    "\n",
    "Look up customer information from your company's internal CRM.\n",
    "\n",
    "Check the inventory level of a product in your e-commerce database.\n",
    "\n",
    "Create a ticket in your project management system (like Jira or Asana).\n",
    "\n",
    "Access patient data from a secure healthcare database.\n",
    "\n",
    "LangChain doesn't have pre-built tools for your specific company's APIs. You would create a custom tool for each of these actions. For example, you could create a get_customer_details tool that takes a customer ID and returns their information.\n",
    "\n",
    "2. To Interact with Local Files and Systems:\n",
    "You might want your agent to perform actions on the local machine where it's running, such as:\n",
    "\n",
    "Reading or writing to a local text file, CSV, or database.\n",
    "\n",
    "Executing a specific command-line script.\n",
    "\n",
    "Interacting with a piece of hardware connected to the system.\n",
    "\n",
    "A custom tool can be created to encapsulate this logic, like a save_note_to_file tool.\n",
    "\n",
    "3. To Implement Complex Business Logic:\n",
    "Some tasks require more than just a single API call; they involve a sequence of steps or complex calculations. You can encapsulate this entire business logic within a single custom tool.\n",
    "\n",
    "For example, a process_new_user_onboarding tool might internally create a user account, send a welcome email, and assign an initial task list. The agent simply needs to call this one tool with the user's details.\n",
    "\n",
    "4. To Provide Access to Specific Knowledge Bases:\n",
    "While LangChain has tools for general knowledge (like Wikipedia), you often need to provide your agent with access to a specialized, private knowledge base. A custom tool can be created to query a vector database (like Qdrant or Pinecone) containing your company's documents, research papers, or product manuals. This is a cornerstone of Retrieval-Augmented Generation (RAG) applications.\n",
    "\n",
    "5. To Integrate with Niche or Specialized Services:\n",
    "The world is full of specialized APIs for everything from weather forecasting and financial data to scientific calculations. If there isn't a pre-built LangChain tool for a service you need, you can easily create a custom tool to act as a wrapper around that service's API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78eb01",
   "metadata": {},
   "source": [
    "How to create tools\n",
    "When constructing an agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:\n",
    "\n",
    "LangChain supports the creation of tools from:\n",
    "\n",
    "1. Functions;\n",
    "2. LangChain Runnables;\n",
    "3. By sub-classing from BaseTool -- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.\n",
    "\n",
    "Creating tools from functions may be sufficient for most use cases, and can be done via a simple @tool decorator. If more configuration is needed-- e.g., specification of both sync and async implementations-- one can also use the StructuredTool.from_function class method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2996dd",
   "metadata": {},
   "source": [
    "## Creating tools from functions\n",
    "`@tool decorator`\n",
    "\n",
    "This @tool decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function's docstring as the tool's description - so a docstring MUST be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5114a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06599ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Multiply two numbers.', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'multiply', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# When you invoke the tool, you can pass the arguments as a dictionary to llm \n",
    "print(multiply.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb4691",
   "metadata": {},
   "source": [
    "## What is async? Asynchronous Programming ⚡\n",
    "The async keyword in Python defines a function as a coroutine. In simple terms, it marks the function as one that can be paused and resumed, allowing other code to run while it's waiting for something to happen.\n",
    "\n",
    "Think of it like cooking in a kitchen:\n",
    "\n",
    "Synchronous (without async): You decide to make pasta. You put the water on to boil and stand there watching it until it boils. Only then do you start chopping vegetables for the sauce. You do one task completely before starting the next. This is inefficient.\n",
    "\n",
    "Asynchronous (with async): You put the water on to boil (an operation that involves waiting). Instead of just standing there, you immediately start chopping your vegetables. When you hear the water boiling, you pause chopping, add the pasta to the water, and then go back to chopping while the pasta cooks. This is much faster.\n",
    "\n",
    "In programming, the \"waiting\" is often for I/O (Input/Output) operations, like making a network request to an API, querying a database, or reading a large file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c07426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an async implementation, like this:\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c307be4",
   "metadata": {},
   "source": [
    "#### Note \n",
    "that @tool supports parsing of annotations, nested schemas, and other features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed955d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Multiply a by the maximum of b.', 'properties': {'a': {'description': 'scale factor', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'list of ints over which to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}}, 'required': ['a', 'b'], 'title': 'multiply_by_max', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int, \"scale factor\"],\n",
    "    b: Annotated[List[int], \"list of ints over which to take maximum\"],\n",
    ") -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "    return a * max(b)\n",
    "\n",
    "\n",
    "print(multiply_by_max.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9deec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication-tool\n",
      "Multiply two numbers.\n",
      "{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#You can also customize the tool name and JSON args by passing them into the tool decorator.\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "@tool(\"multiplication-tool\", args_schema=CalculatorInput, return_direct=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.return_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90bab7",
   "metadata": {},
   "source": [
    "##  Method 2 Structured Tools\n",
    "In LangChain, a Structured Tool is a type of tool designed to interact with Large Language Models (LLMs) in a more controlled and reliable manner by enforcing a predefined input schema. Unlike unstructured tools that might accept free-form string inputs, structured tools require inputs that conform to a specific data structure, often defined using Pydantic models in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0410934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to multiply\")\n",
    "    b: int = Field(required=True, description=\"The second number to multiply\")\n",
    "\n",
    "class AddInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to add\")\n",
    "    b: int = Field(required=True, description=\"The second number to add\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed6bacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\" Multiply two numbers \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a:int, b:int) -> int:\n",
    "    \"\"\" Add two numbers \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be6525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_tool = StructuredTool.from_function(func=multiply,name=\"Multiply\",description=\"Multiplies two numbers\", input_schema=MultiplyInput)\n",
    "add_tool = StructuredTool.from_function(func=add, name=\"Add\", description=\"Adds two numbers\", input_schema=AddInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a281ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multiply = multiply_tool.invoke({\"a\": 2, \"b\": 3})\n",
    "result_add = add_tool.invoke({\"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a8b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Multiply two numbers ',\n",
       " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}},\n",
       " 'required': ['a', 'b'],\n",
       " 'title': 'Multiply',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1825ebe",
   "metadata": {},
   "source": [
    "## To configure it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa92449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Calculator\n",
      "multiply numbers\n",
      "{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "def multiply(a:int,b:int) -> int:\n",
    "    \"\"\" Multiply two numbers \"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    name=\"Calculator\",\n",
    "    description=\"multiply numbers\",\n",
    "    args_schema=CalculatorInput,\n",
    "    return_direct=True,\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(calculator.name)\n",
    "print(calculator.description)\n",
    "print(calculator.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313a46a",
   "metadata": {},
   "source": [
    "## Creating tools from Runnables\n",
    "LangChain Runnables that accept string or dict input can be converted to tools using the as_tool method, which allows for the specification of names, descriptions, and additional schema information for arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "309a96f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'answer_style': {'title': 'Answer Style', 'type': 'string'}},\n",
       " 'required': ['answer_style'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.language_models import GenericFakeChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"Hello. Please respond in the style of {answer_style}.\")]\n",
    ")\n",
    "\n",
    "# Placeholder LLM\n",
    "llm = GenericFakeChatModel(messages=iter([\"hello matey\"]))\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "as_tool = chain.as_tool(\n",
    "    name=\"Style responder\", description=\"Description of when to use tool.\"\n",
    ")\n",
    "as_tool.args_schema.model_json_schema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651656e5",
   "metadata": {},
   "source": [
    "## Subclass BaseTool\n",
    "BaseTool is an abstract class (a blueprint) that all tools in LangChain inherit from.\n",
    "\n",
    "It defines how tools are structured, described, and executed, so that agents can interact with them in a predictable way.\n",
    "\n",
    "Without this standardization, an LLM agent wouldn’t know how to call external functions consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ee9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from typing import Type\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to add\")\n",
    "    b: int = Field(required=True, description=\"The second number to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae2c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyTool(BaseTool):\n",
    "    name: str = \"multiply\"\n",
    "    description: str = \"Multiply two numbers\"\n",
    "\n",
    "    args_schema: Type[BaseModel] = MultiplyInput\n",
    "\n",
    "    def _run(self, a: int, b: int) -> int:\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "328479e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Multiply\n",
      "Multiplies two numbers\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "result = multiply_tool.invoke({'a':3, 'b':3})\n",
    "\n",
    "print(result)\n",
    "print(multiply_tool.name)\n",
    "print(multiply_tool.description)\n",
    "\n",
    "print(multiply_tool.args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
